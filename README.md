# Personalized Anomaly Detection

## Description

This project aims to develop a personalized anomaly detection system using a Neural Stochastic Multi-Modal Point Process (NSMMPP). The goal is to model and detect irregular events in temporal sequences in a way that can be personalized for individual sequences or users.

## Features
- Point process-based event modeling using NSMMPP
- Evaluation metrics including ROC curves and AUC scores
- Easily configurable through YAML files
- Experiment tracking using Aim

## Project Organization
------------

    ├── README.md          <- The top-level README for developers using this project.
    │
    ├── configs            <- Configs files
    |   ├── dataset_config.yaml
    |   ├── main_config.yaml
    |   ├── predict_config.yaml
    │   └── train_config.yaml          
    |
    ├── data
    │   └── raw            <- The original, immutable data dump.
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebook
    │   └── data           <- Data which is used in notebooks
    │
    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment
    │
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data           <- Scripts to generate data and create dataloaders
    │   │   │                 
    │   │   ├── dataloader.py
    │   │   └── make_dataset.py
    │   │
    │   ├── entities       <- Dataclasses for efficient developing, based on configs
    │   │   │                 
    │   │   ├── dataset_params.py
    │   │   ├── main_params.py
    │   │   ├── test_params.py
    │   │   └── train_param.py
    │   │
    │   ├── metrics        <- Scripts to calculate final metrics
    │   │   └── calculate_metrics.py
    │   │
    │   ├── models         <- Scripts to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── baselines.py
    │   │   ├── cppod.py
    │   │   ├── model_manager.py
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    │
    ├── metrics            <- Csv files with final metrics
    ├── .python-version    <- python version for this project, generated by pyenv
    ├── main.py            <- Python script which contains end-to-end pipeline including aim to track and visualise expirements
    └── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io

--------

## Prerequisites

- Python 3.10.11
- Virtual environment (optional but recommended)

## Configuration

You can configure different parts of the project using the YAML files located under the `configs` directory.

- `dataset_config.yaml`: control sythetic dataset generation
- `main_config.yaml`:  parameters for the end-to-end pipeline, which is tracked by Aim
- `predict_config.yaml`: control prediction on a trained model, including the model path(main parameter)
- `train_config.yaml`: conrol model parameters and training process

## Using Hydra and Aim

- **Hydra**: https://hydra.cc/docs/intro/
- **Aim**: https://aimstack.readthedocs.io/en/v3.17.5/

## Installation

Install the required packages by running the following command:

```bash
pip install -r requirements.txt
```

## How to Run

### Data Generation

To generate the dataset, run:

```bash
python -m src.data.make_dataset
```

### Training

To train the model, run:

```bash
python -m src.models.train_model
```

### Prediction

To run prediction on a trained model, run:

```bash
python -m src.models.predict_model
```

### Metrics Calculation

To calculate the metrics, run:

```bash
python -m src.metrics.calculate_metrics
```

### End-to-End Pipeline

To run the end-to-end pipeline with Aim experiment tracking, run:

```bash
python main.py
```

### Custom parameters using Hydra

You can override the default parameters using Hydra. For example, to change the number of hidden units, run:

```bash
python main.py nhid=128
```

### Aim

You can see the results of the experiments using Aim. To run Aim, run:

```bash
aim up
```

## Reports and References

### Reports
For a comprehensive understanding of the methodologies, experiments, and results related to this project, refer to the detailed report available at:
[REPORT.md](reports/REPORT.md)

### References
The development of this project involved the utilization of ideas and code from external sources. All sources have been acknowledged and credited in the references file available at:
[REFERENCES.md](references/REFERENCES.md)
